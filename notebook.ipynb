{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a compiled notebook for alignment of coronal brain slices via STalign (followed up by VisuAlign manual adjustement) and subsequent region boundary export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags:\n",
    "- \"REPLACE ME\": places for user to input their own files (required)\n",
    "- \"CHANGE ME\": places where user can modify behavior (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies #\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pdcm\n",
    "import IPython\n",
    "import os\n",
    "from os.path import exists,split,join,splitext\n",
    "from os import makedirs\n",
    "import glob\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import nrrd\n",
    "import torch\n",
    "from torch.nn.functional import grid_sample\n",
    "import shutil\n",
    "import skimage as ski\n",
    "import STalign\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import rotate\n",
    "import shapely\n",
    "from sklearn.cluster import dbscan\n",
    "import json\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in resources, target images, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Target Image #\n",
    "%matplotlib inline\n",
    "\n",
    "data_folder = \"PASTE PATH TO FOLDER HERE\" #### REPLACE ME #### path to folder with images\n",
    "target_filenames = glob.glob(f\"{data_folder}\\\\*.jpg\")\n",
    "targets_original = []\n",
    "targets_ds = []\n",
    "targets = []\n",
    "\n",
    "for img_filename in target_filenames:\n",
    "    W_original = ski.io.imread(img_filename)\n",
    "    W = W_original.copy()\n",
    "\n",
    "    # uncomment/comment out preprocessing lines as needed, feel free to edit, rearrange, and add your own pre-processing\n",
    "    ds_factor = 1 #### CHANGE ME #### if working with larger image that needs downscaling\n",
    "    W = ski.transform.downscale_local_mean(W, (ds_factor, ds_factor,1)) # downscaling using above factor\n",
    "    W_ds = W.copy().astype('uint8') # save downscaled but not gray scaled image\n",
    "    W = ski.color.rgb2gray(W) # greyscaling rgb image\n",
    "    W = (W - np.min(W)) / (np.max(W) - np.min(W)) # normalizing image\n",
    "    W = 1-W # inverting, optional #### CHANGE ME #### comment/uncomment as needed to ensure image looks good\n",
    "\n",
    "    targets_original.append(W_original)\n",
    "    targets_ds.append(W_ds)\n",
    "    targets.append(W)\n",
    "    print(f'Target Image #{len(targets)} has shape {W.shape}')\n",
    "\n",
    "fig, ax = plt.subplots(len(targets),2,figsize=(8,4*len(targets)))\n",
    "for i in range(len(targets)):\n",
    "    if len(targets) == 1: ax = [ax]\n",
    "    ax[i][0].imshow(targets_original[i])\n",
    "    ax[i][0].set_title(f\"Original Target Image #{i+1}\")\n",
    "    ax[i][1].imshow(targets[i],cmap='Grays')\n",
    "    ax[i][1].set_title(f\"Preprocessed Target Image #{i+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Atlas #\n",
    "# options: DAPI, ALLEN, OTHER \n",
    "# RECOMMENDED: DAPI stained Atlas - https://www.nature.com/articles/s41597-020-0570-z\n",
    "# we use this one because the slices were cryosectioned, stained, and dried on a slide\n",
    "# which is similar to the protocl used in our lab for the experiment this tool was designed for\n",
    "# HOWEVER you can also use the allen atlas if that fits your purposes better, OR you can upload\n",
    "# your own atlas to align to\n",
    "# if you want to use DAPI atlas, keep <chosen_atlas> = 'DAPI',\n",
    "# if you want to use Allen atlas, set <chosen_atlas> = 'ALLEN',\n",
    "# if you want to use another atlas of your choice, set <chosen_atlas> = 'OTHER' AND \n",
    "# fill in your own code for uploading the atlas\n",
    "\n",
    "chosen_atlas = 'DAPI' #### CHANGE ME ####\n",
    "\n",
    "if chosen_atlas == 'DAPI':\n",
    "\n",
    "    reference_img = nib.load(\"Data\\\\Atlases\\\\DAPI\\\\img_dapi.nii\").get_fdata()\n",
    "    reference_labels = nib.load(\"Data\\\\Atlases\\\\DAPI\\\\label_dapi.nii\").get_fdata()\n",
    "\n",
    "    A_original = np.flip(np.transpose(reference_img,(1,2,0)),axis=(0,1))\n",
    "    S = np.flip(np.transpose(reference_labels,(1,2,0)),axis=(0,1))\n",
    "\n",
    "\n",
    "    # downsize for faster stalign then normalize\n",
    "    atlas_ds_factor = (1,4,4) #### CHANGE ME ####\n",
    "    A = ski.transform.downscale_local_mean(A_original, atlas_ds_factor)  \n",
    "    A = np.clip(A, 0, A.max()) # clipping negative values to 0\n",
    "    A = (A - np.min(A)) / (np.max(A) - np.min(A)) # normalize\n",
    "\n",
    "    dxS = [33.34,8.6,8.6] # set pixel dims\n",
    "    dxA = np.multiply(dxS, atlas_ds_factor)\n",
    "    nxA = A.shape\n",
    "\n",
    "    dimAtlas = A.shape\n",
    "    print(\"DAPI Atlas loaded successfully\")\n",
    "\n",
    "elif chosen_atlas == 'ALLEN':\n",
    "\n",
    "    A,_ = nrrd.read(\"Data\\\\Atlases\\\\Allen_50\\\\img_allen_50.nrrd\")\n",
    "    S, hdr = nrrd.read('Data\\\\Atlases\\\\Allen_50\\\\label_allen_50.nrrd')\n",
    "    S = np.array(S,dtype='float64')\n",
    "\n",
    "    A = np.array((A - np.min(A)) / (np.max(A) - np.min(A)),dtype='float64') # normalize\n",
    "\n",
    "    dxA = np.diag(hdr['space directions']) # set pixel dims\n",
    "    dxS = dxA\n",
    "    nxA = A.shape # set dimensions of image\n",
    "\n",
    "    dimAtlas = A.shape\n",
    "    print(\"Allen Atlas loaded successfully\")\n",
    "\n",
    "elif chosen_atlas == 'OTHER':\n",
    "    #### CUSTOM ATLAS UPLOAD ####\n",
    "    # must load reference atlas data as A\n",
    "    # must load labels/segmentation as S\n",
    "    # the reference and the segmentation must be in PIR (Posterior-Inferior-Right) orientation\n",
    "    # must set nxA, the dimensions of A\n",
    "    # must set dxA and dxS, the dimensions of each pixel in micrometers in the reference and labels atlas\n",
    "    # the values of dxA and dxS must correspond to the dimensions of the pixels in the directions that match nxA\n",
    "    # example: if nxA provides dimensions in [anterior-posterior,superior-inferior,left-right], then dxA and dxS must also provide pixel dimensions in the same order\n",
    "    pass #### CHANGE ME ####\n",
    "\n",
    "\n",
    "else: print(\"PLEASE SET <chosen_atlas> to 'DAPI', 'ALLEN', or 'OTHER' \")\n",
    "\n",
    "xA = [np.arange(n)*d - (n-1)*d/2.0 for n,d in zip(nxA,dxA)]\n",
    "XA = np.meshgrid(*xA,indexing='ij')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Affine Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Slice and Rotations #\n",
    "%matplotlib tk\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# poitns stored in z,y,x format\n",
    "deg2rad = lambda deg: np.pi*deg/180\n",
    "rad2deg = lambda rad: 180*rad/np.pi\n",
    "\n",
    "# rotation matrices for along z-axis, y-axis, and x-axis\n",
    "def z_rot(deg):\n",
    "    rads = deg2rad(deg)\n",
    "    return np.array([\n",
    "                        [1,       0       ,         0      ],\n",
    "                        [0, np.cos(rads), -np.sin(rads)],\n",
    "                        [0, np.sin(rads), np.cos(rads) ]\n",
    "                    ])\n",
    "\n",
    "def y_rot(deg):\n",
    "    rads = deg2rad(deg)\n",
    "    return np.array([\n",
    "                        [ np.cos(rads), 0, np.sin(rads)],\n",
    "                        [        0      , 1,     0         ],\n",
    "                        [-np.sin(rads), 0, np.cos(rads)]\n",
    "                    ])\n",
    "\n",
    "def x_rot(deg):\n",
    "    rads = deg2rad(deg)\n",
    "    return np.array([\n",
    "                        [np.cos(rads), -np.sin(rads), 0],\n",
    "                        [np.sin(rads),  np.cos(rads), 0],\n",
    "                        [       0      ,        0       , 1]\n",
    "                    ])\n",
    "\n",
    "# get an affine matrix for a given set of rotations\n",
    "def get_L(thetas):\n",
    "    # thetas follows [z,y,x] format where 'z' represents rotations about the z axis\n",
    "    L_estim = np.array([[1,0,0],\n",
    "                        [0,1,0],\n",
    "                        [0,0,1]])\n",
    "                        \n",
    "    L_estim = L_estim@x_rot(thetas[2])\n",
    "    L_estim = L_estim@y_rot(thetas[1])\n",
    "    L_estim = L_estim@z_rot(thetas[0])\n",
    "    return(L_estim)\n",
    "\n",
    "# output msgs cleanly\n",
    "def msg(msg):\n",
    "    clear_output()\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "# setting \n",
    "if 'T_estim' not in locals(): # keep translation from previous runs\n",
    "    T_estim = np.array([[0, 0, 0] for i in targets])\n",
    "\n",
    "if 'thetas' not in locals(): #avoid wiping out thetas from  previous runs\n",
    "    thetas = np.array([[0,0,0] for i in targets]) # z, y, x order\n",
    "alpha = 1.25 # factor to expand meshgrid dimensions by to allow for rotation\n",
    "xE = [alpha*x for x in xA]\n",
    "XE = np.stack(np.meshgrid(np.zeros(1),xE[1],xE[2],indexing='ij'),-1)\n",
    "\n",
    "nS = S.shape\n",
    "xS = [np.arange(n)*d - (n-1)*d/2  for n,d in zip(nS, dxS)]\n",
    "\n",
    "## Handle showing atlas ##\n",
    "slice_from_T = lambda T: T/dxA[0] + A.shape[0]/2\n",
    "T_from_slice = lambda slice: dxA[0]*(slice - A.shape[0]/2)\n",
    "def atlas_img(thetas,T):\n",
    "    slice_t = (get_L(thetas) @ XE[...,None])[...,0] + T\n",
    "    img = STalign.interp3D(xA, A[None].astype('float64'), \n",
    "                           slice_t.transpose(3,0,1,2))[0,0,...]\n",
    "    #if chosen_atlas == 'ALLEN': return 1-img.numpy()\n",
    "    return img.numpy()\n",
    "\n",
    "def seg_img(thetas, T):\n",
    "    slice_t = (get_L(thetas)@XE[...,None])[...,0] + T\n",
    "    img = STalign.interp3D(xS, S[None].astype('float64'), \n",
    "                           slice_t.transpose(3,0,1,2), \n",
    "                           mode='nearest')[0,0,...]\n",
    "    return img.numpy()\n",
    "\n",
    "## Event Handling ##\n",
    "\n",
    "class Affine_estimator:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # creating figures\n",
    "        self.fig, self.ax = plt.subplots(1,2)\n",
    "        self.fig.subplots_adjust(left=0.2)\n",
    "        self.index = 0\n",
    "        self.show_atlas()\n",
    "        self.show_target()\n",
    "\n",
    "        # adding prev and next button\n",
    "        ax_prev = self.fig.add_axes([0.7,0.05,0.1,0.1])\n",
    "        ax_next = self.fig.add_axes([0.8,0.05,0.1,0.1])\n",
    "        self.prev_btn = mpl.widgets.Button(ax_prev, label='Previous')\n",
    "        self.next_btn = mpl.widgets.Button(ax_next, label='Next')\n",
    "        self.prev_btn.on_clicked(self.on_prev)\n",
    "        self.next_btn.on_clicked(self.on_next)\n",
    "\n",
    "        # adding sliders for rotation\n",
    "        ax_x = self.fig.add_axes([0.05,0.2,0.03,0.7])\n",
    "        ax_y = self.fig.add_axes([0.1,0.2,0.03,0.7])\n",
    "        ax_z = self.fig.add_axes([0.15,0.2,0.03,0.7])\n",
    "        self.degrees_x = mpl.widgets.Slider(ax_x,'x', valmin=-90, valmax=90, valinit=0, valstep=1, orientation='vertical')\n",
    "        self.degrees_y = mpl.widgets.Slider(ax_y,'y', valmin=-90, valmax=90, valinit=0, valstep=1, orientation='vertical')\n",
    "        self.degrees_z = mpl.widgets.Slider(ax_z,'z', valmin=-180, valmax=180, valinit=0, valstep=1, orientation='vertical')\n",
    "        self.degrees_x.on_changed(self.rot_x)\n",
    "        self.degrees_y.on_changed(self.rot_y)\n",
    "        self.degrees_z.on_changed(self.rot_z)\n",
    "\n",
    "        # adding slider for translation\n",
    "        ax_t = self.fig.add_axes([0.2, 0.05, 0.4, 0.03])\n",
    "        self.translation = mpl.widgets.Slider(ax_t, 'slice  ', valmin=0, valmax=A.shape[0], valinit=A.shape[0]//2)\n",
    "        self.translation.on_changed(self.translate)\n",
    "\n",
    "        self.set_sliders()\n",
    "\n",
    "        self.fig.canvas.mpl_connect('key_press_event', self.on_press)\n",
    "\n",
    "    def on_press(self, event):\n",
    "        if event.key=='backspace': \n",
    "            thetas[self.index] = np.array([0,0,0])\n",
    "            T_estim[self.index,0] = 0\n",
    "            self.show_atlas()\n",
    "            self.set_sliders()\n",
    "\n",
    "    def translate(self, slice):\n",
    "        T_estim[self.index,0] = T_from_slice(slice)\n",
    "        self.show_atlas()\n",
    "    \n",
    "    def rot_x(self, angle):\n",
    "        thetas[self.index,2] = angle\n",
    "        self.show_atlas()\n",
    "\n",
    "    def rot_y(self, angle):\n",
    "        thetas[self.index,1] = angle\n",
    "        self.show_atlas()\n",
    "\n",
    "    def rot_z(self, angle):\n",
    "        thetas[self.index,0] = angle\n",
    "        self.show_atlas()\n",
    "\n",
    "    def show_target(self):\n",
    "        img = targets[self.index]\n",
    "        self.ax[1].clear()\n",
    "        self.ax[1].imshow(img,cmap='Grays')\n",
    "        self.ax[1].set_title(f'Target img #{self.index+1}')\n",
    "        self.ax[1].set_axis_off()\n",
    "        plt.draw()\n",
    "\n",
    "    def show_atlas(self):\n",
    "        img = atlas_img(thetas[self.index],T_estim[self.index])\n",
    "        self.ax[0].cla()\n",
    "        self.ax[0].imshow(img, cmap='Grays')\n",
    "        self.ax[0].set_title(f'Atlas Slice {int(slice_from_T(T_estim[self.index,0]))}/{len(A)}')\n",
    "        self.ax[0].set_axis_off()\n",
    "        plt.draw()\n",
    "\n",
    "    def set_sliders(self):\n",
    "        self.degrees_x.set_val(thetas[self.index,2])\n",
    "        self.degrees_y.set_val(thetas[self.index,1])\n",
    "        self.degrees_z.set_val(thetas[self.index,0])\n",
    "        self.translation.set_val(slice_from_T(T_estim[self.index,0]))\n",
    "\n",
    "    def on_prev(self,event):\n",
    "        self.index -= 1\n",
    "        self.index %= len(targets)\n",
    "        self.show_target()\n",
    "        self.show_atlas()\n",
    "        self.set_sliders()\n",
    "\n",
    "    def on_next(self,event):\n",
    "        self.index += 1\n",
    "        self.index %= len(targets)\n",
    "        self.show_target()\n",
    "        self.show_atlas()\n",
    "        self.set_sliders()\n",
    "\n",
    "######################### CONTROLS ########################\n",
    "# scroll up/down: incr/decr slice                         #\n",
    "# arrow left/right: rot y-axis cw/ccw (top-down view)     #\n",
    "# arrow up/down: rot x-axis cw/ccw (right side view)      #\n",
    "# mouse click left/right: rot z-axis ccw/cw (frontal vew) #\n",
    "###########################################################\n",
    "\n",
    "# show atlas and target image\n",
    "interface = Affine_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images of estimated slice to use in future steps #\n",
    "# WARNING: this cell may take up to 1 minute to run, if it takes a while to run, DO NOT STOP IT, let it run its course\n",
    "L_estim = np.array([get_L(theta) for theta in thetas])\n",
    "slice_imgs = [atlas_img(theta,T) for theta,T in zip(thetas, T_estim)]\n",
    "slice_labels = [seg_img(theta,T) for theta,T in zip(thetas, T_estim)]\n",
    "bounds = [ski.segmentation.find_boundaries(sl) for sl in slice_labels]\n",
    "slice_segs = [ski.segmentation.mark_boundaries(si, sl.astype('int'),color=(0,0,255),mode='inner') for si,sl in zip(slice_imgs, slice_labels)]\n",
    "\n",
    "print(f\"ESTIMATED AFFINE (L)\\n{L_estim}\\nRotation along z,y,x axes respectively:{thetas}\\nTranslation along z,y,x axes respectively (um):{T_estim}:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the voxel dimensions of the target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Voxel Dimensions #\n",
    "# If you know the pixel dimensions of your image, you can add them here, if not, leave it at 0\n",
    "# The first element should be the length of each pixel in the superior-inferior direction\n",
    "# The second element should be the length of each pixel in the left-right direction\n",
    "%matplotlib tk\n",
    "pixdim = [0,0] #### CHANGE ME #### format should be [height (um), width (um)]\n",
    "dxW = pixdim*ds_factor\n",
    "estimate_dxW = (np.prod(dxW)==0) # if true, need to estimate, else no need to estimate\n",
    "\n",
    "# this lambda function returns the contour for a given image, given a specific threshold\n",
    "def contour (img, threshold):\n",
    "    contours = ski.measure.find_contours(img, threshold)\n",
    "    return sorted(contours, key=lambda c: shapely.Polygon(c).area)[-1]\n",
    "\n",
    "if estimate_dxW:\n",
    "    # you'll have to play with this number to achieve a good contour of your target image\n",
    "    contour_threshold = .1 #### CHANGE ME #### (between 0-1)\n",
    "    sample_img_index = 0 #### CHANGE ME #### choose a different one of the target images if it's hard to find a contour for this\n",
    "    cA = contour(slice_imgs[sample_img_index], 0.1)\n",
    "    cT = contour(targets[sample_img_index], contour_threshold)\n",
    "\n",
    "    # we use this contour to estimate the scale of your image with respect to the atlas,\n",
    "    # which allows us to estimate the dimensions\n",
    "    area_A = shapely.Polygon(cA).area\n",
    "    area_T = shapely.Polygon(cT).area\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].imshow(slice_imgs[sample_img_index], cmap='Grays')\n",
    "    ax[1].imshow(targets[sample_img_index], cmap='Grays')\n",
    "\n",
    "    ax[0].plot(cA[:,1], cA[:,0],c='r')\n",
    "    ax[1].plot(cT[:,1], cT[:,0],c='r')\n",
    "\n",
    "    # scale based on ratio of areas\n",
    "    scale = np.sqrt(area_T / area_A) / alpha # must also correct for expansion of atlas dimensions from alpha\n",
    "    print(f'Scale: {scale}')\n",
    "    dxW = (1/scale)*dxA[1:]\n",
    "    print(f'Estimated pixel dimensions of target images: {dxW}')\n",
    "\n",
    "xJs = [[np.arange(n)*d - (n-1)*d/2.0 for n,d in zip(W.shape,dxW)] for W in targets]\n",
    "Js = [W[None]/np.mean(np.abs(W)) for W in targets]\n",
    "xI = xA\n",
    "I = A[None] / np.mean(np.abs(A),keepdims=True)\n",
    "I = np.concatenate((I,(I-np.mean(I))**2)) # comment this line out when using stalign_no_contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotating Landmark Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point Annotator #\n",
    "# left side is atlas slice\n",
    "# right side is target image\n",
    "# use mouse left click to mark a pair of corresponding points on atlas and target\n",
    "# right click removes the point\n",
    "# enter commits points to list\n",
    "# backspace removes most recently committed point\n",
    "# ctrl+backspace clears all points\n",
    "# COLOR KEY\n",
    "# red: new marked point, not committed\n",
    "# orange: most recently committed point, will be removed with backspace\n",
    "# black: committed point\n",
    "# when done selecting and committing points, simply move on to next cell\n",
    "%matplotlib tk\n",
    "if 'points' not in locals(): # avoid wiping out points from previous runs of this cell\n",
    "    points = [[[],[]] for t in targets]\n",
    "\n",
    "extentAtlasSlice = STalign.extent_from_x(xE[1:])\n",
    "extents_target = [STalign.extent_from_x(xJ) for xJ in xJs]\n",
    "new_pts = [[[],[]] for t in targets]\n",
    "\n",
    "class Point_Annotator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.index = 0\n",
    "        self.pt_sz = 4\n",
    "        self.show_seg = False\n",
    "\n",
    "        self.fig, self.ax = plt.subplots(1,2)\n",
    "        self.fig.subplots_adjust(left=0.2)\n",
    "        self.show_atlas()\n",
    "        self.show_target()\n",
    "\n",
    "        # adding prev and next button\n",
    "        ax_prev = self.fig.add_axes([0.7,0.05,0.1,0.1])\n",
    "        ax_next = self.fig.add_axes([0.8,0.05,0.1,0.1])\n",
    "        self.prev_btn = mpl.widgets.Button(ax_prev, label='Previous')\n",
    "        self.next_btn = mpl.widgets.Button(ax_next, label='Next')\n",
    "        self.prev_btn.on_clicked(self.on_prev)\n",
    "        self.next_btn.on_clicked(self.on_next)\n",
    "\n",
    "        self.fig.canvas.mpl_connect('button_press_event', self.onclick)\n",
    "        self.fig.canvas.mpl_connect('key_press_event', self.on_press)\n",
    "\n",
    "    def show_target(self):\n",
    "        img = targets[self.index]\n",
    "        self.ax[1].clear()\n",
    "        self.ax[1].set_title(f'Target img #{self.index+1}')\n",
    "        self.ax[1].imshow(img,cmap='Grays', extent=extents_target[self.index])\n",
    "        if len(points[self.index][1]):\n",
    "            self.ax[1].scatter(np.array(points[self.index])[1,:, 1], np.array(points[self.index])[1,:, 0], color='lime', s=self.pt_sz)\n",
    "            self.ax[1].scatter(np.array(points[self.index])[1,-1, 1], np.array(points[self.index])[1,-1, 0], color='orange', s=self.pt_sz)\n",
    "        if len(new_pts[self.index][1]):\n",
    "            self.ax[1].scatter(new_pts[self.index][1][1], new_pts[self.index][1][0], color='red', s=self.pt_sz)\n",
    "        plt.draw()\n",
    "\n",
    "    def show_atlas(self):\n",
    "        if self.show_seg: img = slice_segs[self.index]\n",
    "        else: img = slice_imgs[self.index]\n",
    "        self.ax[0].clear()\n",
    "        self.ax[0].set_title(f'Atlas Slice {int(slice_from_T(T_estim[self.index,0]))}/{len(A)}')\n",
    "        self.ax[0].imshow(img, cmap='Grays', extent=extentAtlasSlice)\n",
    "        if len(points[self.index][0]):\n",
    "            self.ax[0].scatter(np.array(points[self.index])[0,:, 1], np.array(points[self.index])[0,:, 0], color='lime', s=self.pt_sz)\n",
    "            self.ax[0].scatter(np.array(points[self.index])[0,-1, 1], np.array(points[self.index])[0,-1, 0], color='orange', s=self.pt_sz)\n",
    "        if len(new_pts[self.index][0]):\n",
    "            self.ax[0].scatter(new_pts[self.index][0][1], new_pts[self.index][0][0], color='red', s=self.pt_sz)\n",
    "        plt.draw()\n",
    "\n",
    "    def on_prev(self,event):\n",
    "        self.index -= 1\n",
    "        self.index %= len(targets)\n",
    "        self.show_target()\n",
    "        self.show_atlas()\n",
    "\n",
    "    def on_next(self,event):\n",
    "        self.index += 1\n",
    "        self.index %= len(targets)\n",
    "        self.show_target()\n",
    "        self.show_atlas()\n",
    "\n",
    "    def onclick(self, event):\n",
    "\n",
    "        if event.button == 2: \n",
    "            self.show_seg = not self.show_seg\n",
    "            msg(\"Toggled segmentation\")\n",
    "            self.show_atlas()\n",
    "            return\n",
    "            \n",
    "        if event.xdata == None: return # clicked outside of plot\n",
    "        ix, iy = int(event.xdata), int(event.ydata) # get x and y data of pt\n",
    "        message = f'[{ix}, {iy}]'\n",
    "        \n",
    "        axis = -1\n",
    "        # based on where user clicked, set axis and update output message\n",
    "        if event.inaxes == self.ax[0]:\n",
    "            axis = 0\n",
    "            message = \"source at \" + message\n",
    "        elif event.inaxes == self.ax[1]:\n",
    "            axis = 1\n",
    "            message = \"target at \" + message\n",
    "        else: return\n",
    "\n",
    "        if event.button == 1: # left click means add point at mouse location\n",
    "            new_pts[self.index][axis] = [iy, ix]\n",
    "            message = 'point added to ' + message\n",
    "        elif event.button == 3: # right click means remove previously created point\n",
    "            new_pts[self.index][axis] = []\n",
    "            message = 'point removed from ' + message\n",
    "\n",
    "        msg(message)\n",
    "        # refresh that axis to clear out any previously clicked on pts that were not committed\n",
    "        if axis == 0: self.show_atlas() # refresh atlas\n",
    "        if axis == 1: self.show_target() # refresh target\n",
    "\n",
    "\n",
    "    def on_press(self, event):\n",
    "        if event.key == 'enter': # enter key used to commit selected points to points list\n",
    "\n",
    "            if not len(new_pts[self.index][0])*len(new_pts[self.index][1]): # if missing a point in either axis, throw error\n",
    "                print(\"ERROR: attempted landmark save with one or more points missing!\")\n",
    "                return\n",
    "\n",
    "            # add new points to list, notify user, and clear out new points list\n",
    "            points[self.index][0].append(new_pts[self.index][0])\n",
    "            points[self.index][1].append(new_pts[self.index][1])\n",
    "            msg(f\"Added [{new_pts[self.index][0]}] and [{new_pts[self.index][1]}] to points list.\\n{len(points[self.index][0])} marked points\")\n",
    "            new_pts[self.index][0] = []\n",
    "            new_pts[self.index][1] = []\n",
    "            \n",
    "            # refresh both axes\n",
    "            self.show_atlas() \n",
    "            self.show_target()\n",
    "\n",
    "        elif event.key == 'backspace': # backspace key used to remove recently committed point\n",
    "            if len(points[self.index][0]) == 0: return # if no points to remove, simply return\n",
    "            msg(f'Removed [{points[self.index][0][-1]}] and [{points[self.index][1][-1]}]\\n{len(points[self.index][0])-1} marked points') # user msg\n",
    "            \n",
    "            # remove last pair of poins\n",
    "            points[self.index][0].pop(-1)\n",
    "            points[self.index][1].pop(-1)\n",
    "            \n",
    "            # refresh both axes\n",
    "            self.show_atlas() \n",
    "            self.show_target()\n",
    "            \n",
    "        elif event.key == 'ctrl+backspace': #ctr+backspace to remove all poins\n",
    "            if len(points[self.index][0]) == 0: return # if no points to remove, simply return\n",
    "            msg('Removed all points')\n",
    "            points[self.index][0] = []\n",
    "            points[self.index][1] = []\n",
    "            new_pts[self.index][0] = []\n",
    "            new_pts[self.index][1] = []\n",
    "            \n",
    "            self.show_atlas() \n",
    "            self.show_target()\n",
    "\n",
    "# output msgs cleanly\n",
    "def msg(msg):\n",
    "    clear_output()\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "interface = Point_Annotator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Points #\n",
    "%matplotlib inline\n",
    "points_np = [np.array(s) for s in points]\n",
    "slice_pts = [(get_L(thetas[index])@XE[...,None])[...,0] + T_estim[index] for index in range(len(targets))]\n",
    "x_to_pix = lambda x: (x-xE[2][0])/alpha/dxA[2]\n",
    "y_to_pix = lambda y: (y-xE[1][0])/alpha/dxA[1]\n",
    "\n",
    "pts_atlas_pix = [np.array([[y_to_pix(px[0]), x_to_pix(px[1])] for px in points[index][0]]).astype(int) for index in range(len(targets))] # get pixel locations of points on atlas\n",
    "points_atlas = [slice_pts[index][0, pts[:,0], pts[:,1]] if points_np[index].shape[1] else None for index, pts in enumerate(pts_atlas_pix)] # convert that to points pointed to by sampling array (slice_pts)\n",
    "points_target = [np.insert(points_np[index][1],0,0,axis=1) if points_np[index].shape[1] else None for index in range(len(targets))]\n",
    "\n",
    "# plot points to confirm\n",
    "fig, ax = plt.subplots(len(targets),2, figsize=(10,4*len(targets)))\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.2)\n",
    "for i in range(len(targets)):\n",
    "    if len(targets) == 1: ax = [ax]\n",
    "    ax[i][0].imshow(slice_imgs[i], extent=extentAtlasSlice, cmap='Grays')\n",
    "    ax[i][1].imshow(targets[i], extent=extents_target[i], cmap='Grays')\n",
    "\n",
    "    if points_np[i].shape[1]:\n",
    "        ax[i][0].scatter(points_np[i][0,:,1], points_np[i][0,:,0], color='red', s=5)\n",
    "        ax[i][1].scatter(points_np[i][1,:,1], points_np[i][1,:,0], color='red', s=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running STalign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Parameters For STalign #\n",
    "# specify device (default device for STalign.LDDMM is cpu)\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "scale_x = 1\n",
    "scale_y = 1\n",
    "scale_z = 1\n",
    "\n",
    "Ls = np.array([np.linalg.inv(Li) for Li in L_estim])\n",
    "Ts = -T_estim\n",
    "scale_atlas = np.array([[scale_z,0,0],\n",
    "                        [0,scale_y,0],\n",
    "                        [0,0,scale_x]])\n",
    "Ls = np.matmul(Ls,scale_atlas)\n",
    "\n",
    "#### CHANGE ME ####\n",
    "# Adjust default settings for hyperparameters here\n",
    "default_nt = 12 # number of time steps, increase for smoother transform at expense of time\n",
    "default_niter = 100 # number of gradient descent iterations suggested: 100, 'gold standard' is 2000 but takes 1hr to run\n",
    "default_sigmaM = .5 # matching error -> increase to de-emphasize it# matching error -> increase to de-emphasize it\n",
    "default_sigmaP = 1 # points error -> increase to de-emphasize it\n",
    "default_sigmaR = 1e8 # regularization error -> increase to de-emphasize it\n",
    "default_a = 250 # resolution of alignment -> increase to speed up alignment at expense of fine alignment, decrease to improve fine alignment at expense of time\n",
    "####################\n",
    "\n",
    "# creating an array for each hyperparameter for each slice\n",
    "nts = [default_nt for i in range(len(targets))]\n",
    "nts = [default_nt for i in range(len(targets))]\n",
    "niters = [default_niter for i in range(len(targets))]\n",
    "sigmaMs = [default_sigmaM for i in range(len(targets))]\n",
    "sigmaPs = [default_sigmaP for i in range(len(targets))]\n",
    "sigmaRs = [default_sigmaR for i in range(len(targets))]\n",
    "a_s = [default_a for i in range(len(targets))]\n",
    "\n",
    "###### Adjust individual values here ######\n",
    "# For example, to adjust the sigmaM of the 5th slice to 10,\n",
    "# sigmaMs[4] = 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTION DEFINITIONS ###\n",
    "\n",
    "# for LDDMM_LBGFS\n",
    "def LDDMM_3D_LBGFS(xI,I,xJ,J,pointsI=None,pointsJ=None,\n",
    "        L=None,T=None,A=None,v=None,xv=None,\n",
    "        a=500.0,p=2.0,expand=1.25,nt=3,\n",
    "        niter=5000,diffeo_start=0, epL=1e-6, epT=1e1, epV=1e3,\n",
    "        sigmaM=1.0,sigmaB=2.0,sigmaA=5.0,sigmaR=1e8,sigmaP=2e1,\n",
    "        device='cpu',dtype=torch.float64, muA=None, muB = None):\n",
    "\n",
    "        \n",
    "    # check initial inputs and convert to torch\n",
    "    if A is not None:\n",
    "        # if we specify an A\n",
    "        if L is not None or T is not None:\n",
    "            raise Exception('If specifying A, you must not specify L or T')\n",
    "        L = torch.tensor(A[:3,:3],device=device,dtype=dtype,requires_grad=True)\n",
    "        T = torch.tensor(A[:3,-1],device=device,dtype=dtype,requires_grad=True)   \n",
    "    else:\n",
    "        # if we do not specify A                \n",
    "        if L is None: L = torch.eye(3,device=device,dtype=dtype,requires_grad=True)\n",
    "        if T is None: T = torch.zeros(3,device=device,dtype=dtype,requires_grad=True)\n",
    "    \n",
    "    L = torch.tensor(L,device=device,dtype=dtype,requires_grad=True)\n",
    "    T = torch.tensor(T,device=device,dtype=dtype,requires_grad=True)\n",
    "    # change to torch\n",
    "    I = torch.tensor(I,device=device,dtype=dtype)                         \n",
    "    J = torch.tensor(J,device=device,dtype=dtype)\n",
    "    if J.ndim == 3:\n",
    "        J = J[:,None] # add a z slice dimension\n",
    "\n",
    "\n",
    "    if v is not None and xv is not None:\n",
    "        v = torch.tensor(v,device=device,dtype=dtype,requires_grad=True)\n",
    "        xv = [torch.tensor(x,device=device,dtype=dtype) for x in xv]\n",
    "        XV = torch.stack(torch.meshgrid(xv),-1)\n",
    "        nt = v.shape[0]        \n",
    "    elif v is None and xv is None:\n",
    "        minv = torch.as_tensor([x[0] for x in xI],device=device,dtype=dtype)\n",
    "        maxv = torch.as_tensor([x[-1] for x in xI],device=device,dtype=dtype)\n",
    "        minv,maxv = (minv+maxv)*0.5 + 0.5*torch.tensor([-1.0,1.0],device=device,dtype=dtype)[...,None]*(maxv-minv)*expand\n",
    "        xv = [torch.arange(m,M,a*0.5,device=device,dtype=dtype) for m,M in zip(minv,maxv)]\n",
    "        XV = torch.stack(torch.meshgrid(xv),-1)\n",
    "        v = torch.zeros((nt,XV.shape[0],XV.shape[1],XV.shape[2],XV.shape[3]),device=device,dtype=dtype,requires_grad=True)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(f'If inputting an initial v, must input both xv and v')\n",
    "    extentV = STalign.extent_from_x(xv[1:])\n",
    "    dv = torch.as_tensor([x[1]-x[0] for x in xv],device=device,dtype=dtype)\n",
    "    \n",
    "    fv = [torch.arange(n,device=device,dtype=dtype)/n/d for n,d in zip(XV.shape,dv)]\n",
    "    extentF = STalign.extent_from_x(fv[1:])\n",
    "    FV = torch.stack(torch.meshgrid(fv),-1)\n",
    "    LL = (1.0 + 2.0*a**2* torch.sum( (1.0 - torch.cos(2.0*np.pi*FV*dv))/dv**2 ,-1))**(p*2.0)\n",
    "\n",
    "    K = 1.0/LL\n",
    "    #fig,ax = plt.subplots()\n",
    "    #ax.imshow(K,vmin=0.0,vmax=0.1,extent=extentF)\n",
    "    \n",
    "    #fig,ax = plt.subplots()\n",
    "    #ax.imshow(K[0].cpu())\n",
    "    DV = torch.prod(dv)\n",
    "    Ki = torch.fft.ifftn(K).real\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.imshow(Ki[Ki.shape[0]//2].clone().detach().cpu().numpy(),vmin=0.0,extent=extentV)\n",
    "    ax.set_title('smoothing kernel')\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # initialize weights\n",
    "    WM = torch.ones(J[0].shape,dtype=J.dtype,device=J.device)*0.5\n",
    "    WB = torch.ones(J[0].shape,dtype=J.dtype,device=J.device)*0.4\n",
    "    WA = torch.ones(J[0].shape,dtype=J.dtype,device=J.device)*0.1\n",
    "\n",
    "    # locations of pixels\n",
    "    extentI = STalign.extent_from_x(xI[1:]) \n",
    "    xI = [torch.tensor(x,device=device,dtype=dtype) for x in xI]\n",
    "    if len(xJ) == 2:\n",
    "        xJ = [[0.0],xJ[0],xJ[1]]    \n",
    "    extentJ = STalign.extent_from_x(xJ[1:])\n",
    "    xJ = [torch.tensor(x,device=device,dtype=dtype) for x in xJ]\n",
    "    XI = torch.stack(torch.meshgrid(*xI,indexing='ij'),-1)\n",
    "    XJ = torch.stack(torch.meshgrid(*xJ,indexing='ij'),-1)\n",
    "    dJ = [x[1]-x[0] for x in xJ[1:]]\n",
    "\n",
    "    # a figure\n",
    "    fig,ax = plt.subplots(2,3)\n",
    "    ax = ax.ravel()\n",
    "    if type(pointsI) != type(None): figE,axE = plt.subplots(1,4)\n",
    "    else: figE,axE = plt.subplots(1,3)\n",
    "    axE = axE.ravel()\n",
    "    Esave = []\n",
    "    # zero gradients\n",
    "    try:\n",
    "        L.grad.zero_()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        T.grad.zero_()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if pointsI is None and pointsJ is None:\n",
    "        pointsI = torch.zeros((0,2),device=J.device,dtype=J.dtype)\n",
    "        pointsJ = torch.zeros((0,2),device=J.device,dtype=J.dtype)\n",
    "    elif (pointsI is None and pointsJ is not None) or (pointsJ is None and pointsI is not None):\n",
    "        raise Exception('Must specify corresponding sets of points or none at all')\n",
    "    else:\n",
    "        pointsI = torch.tensor(pointsI,device=J.device,dtype=J.dtype)\n",
    "        pointsJ = torch.tensor(pointsJ,device=J.device,dtype=J.dtype)\n",
    "\n",
    "    optimizer = torch.optim.Adam([L, T,v], lr=1e-3)#, max_iter=4, line_search_fn=\"strong_wolfe\")\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        A = STalign.to_A_3D(L,T)\n",
    "\n",
    "        # Ai\n",
    "        Ai = torch.linalg.inv(A)\n",
    "        # transform sample points        \n",
    "        Xs = (Ai[:-1,:-1]@XJ[...,None])[...,0] + Ai[:-1,-1]\n",
    "        \n",
    "        # now diffeo, not semilagrange here\n",
    "        for t in range(nt-1,-1,-1):\n",
    "            Xs = Xs + STalign.interp3D(xv,-v[t].permute(3,0,1,2),Xs.permute(3,0,1,2)).permute(1,2,3,0)/nt\n",
    "        \n",
    "        # and points\n",
    "        pointsIt = torch.clone(pointsI)\n",
    "        if pointsIt.shape[0] >0:\n",
    "            for t in range(nt):\n",
    "                pointsIt += (STalign.interp3D(xv,v[t].permute(3,0,1,2),pointsIt.T[...,None,None])[...,0,0].T/nt)\n",
    "            pointsIt = (A[:-1,:-1]@pointsIt.T + A[:-1,-1][...,None]).T \n",
    "       \n",
    "        # transform image\n",
    "        AI = STalign.interp3D(xI,I,Xs.permute(3,0,1,2),padding_mode=\"border\")\n",
    "\n",
    "        fAI = AI\n",
    "        # objective function\n",
    "        EM = torch.sum((fAI - J)**2*WM)/2.0/sigmaM**2\n",
    "        ER = torch.sum(torch.sum(torch.abs(torch.fft.fftn(v,dim=(1,2)))**2,dim=(0,-1))*LL)*DV/2.0/v.shape[1]/v.shape[2]/sigmaR**2\n",
    "            \n",
    "        E = EM + ER\n",
    "        \n",
    "        if pointsIt.shape[0]>0:\n",
    "            EP = torch.sum((pointsIt - pointsJ)**2)/2.0/sigmaP**2\n",
    "            E += EP\n",
    "\n",
    "        E.backward(retain_graph=True)\n",
    "        return E\n",
    "    \n",
    "    for it in range(niter):\n",
    "        print(f'Iteration #{it}:')\n",
    "\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        optimizer.zero_grad()        \n",
    "        # make A\n",
    "        A = STalign.to_A_3D(L,T)\n",
    "\n",
    "        # Ai\n",
    "        Ai = torch.linalg.inv(A)\n",
    "        # transform sample points        \n",
    "        Xs = (Ai[:-1,:-1]@XJ[...,None])[...,0] + Ai[:-1,-1]\n",
    "        # now diffeo, not semilagrange here\n",
    "        for t in range(nt-1,-1,-1):\n",
    "            #print(Xs.shape)\n",
    "            Xs = Xs + STalign.interp3D(xv,-v[t].permute(3,0,1,2),Xs.permute(3,0,1,2)).permute(1,2,3,0)/nt\n",
    "        # # and points (not in 3D)        \n",
    "        #print(np.shape(pointsI))\n",
    "        \n",
    "        pointsIt = torch.clone(pointsI)\n",
    "        if pointsIt.shape[0] >0:\n",
    "            for t in range(nt):\n",
    "                pointsIt += (STalign.interp3D(xv,v[t].permute(3,0,1,2),pointsIt.T[...,None,None])[...,0,0].T/nt)\n",
    "            pointsIt = (A[:-1,:-1]@pointsIt.T + A[:-1,-1][...,None]).T\n",
    "        \n",
    "        # transform image\n",
    "        AI = STalign.interp3D(xI,I,Xs.permute(3,0,1,2),padding_mode=\"border\")\n",
    "\n",
    "        fAI = AI\n",
    "        # objective function\n",
    "        EM = torch.sum((fAI - J)**2*WM)/2.0/sigmaM**2\n",
    "        ER = torch.sum(torch.sum(torch.abs(torch.fft.fftn(v,dim=(1,2)))**2,dim=(0,-1))*LL)*DV/2.0/v.shape[1]/v.shape[2]/sigmaR**2\n",
    "        #if pointsIt.shape[0]>0: EP = torch.sum((pointsIt_t - pointsJt)**2)/2.0/sigmaP**2\n",
    "            \n",
    "        E = EM + ER #+ EP\n",
    "        tosave = [E.item(), EM.item(), ER.item()]\n",
    "        \n",
    "        if pointsIt.shape[0]>0:\n",
    "            EP = torch.sum((pointsIt - pointsJ)**2)/2.0/sigmaP**2\n",
    "            E += EP\n",
    "            tosave.append(EP.item())\n",
    "    \n",
    "        E.backward()\n",
    "        optimizer.step()\n",
    "        Esave.append( tosave )\n",
    "        # gradient update\n",
    "        '''try:\n",
    "            L.grad.zero_()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            T.grad.zero_()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            v.grad.zero_()\n",
    "        except:\n",
    "            pass'''\n",
    "        '''E.backward()\n",
    "\n",
    "        with torch.no_grad():            \n",
    "            L -= (epL/(1.0 + (it>=diffeo_start)*9))*L.grad\n",
    "            T -= (epT/(1.0 + (it>=diffeo_start)*9))*T.grad\n",
    "\n",
    "            #L.grad.zero_()\n",
    "            #T.grad.zero_()\n",
    "\n",
    "            # v grad\n",
    "            vgrad = v.grad\n",
    "            # smooth it            \n",
    "            if it >= diffeo_start:\n",
    "                vgrad = torch.fft.ifftn(torch.fft.fftn(vgrad,dim=(1,2,3))*K[...,None],dim=(1,2,3)).real\n",
    "                v -= vgrad*epV'''\n",
    "            #v.grad.zero_()\n",
    "\n",
    "    # draw\n",
    "    if it == niter-1:\n",
    "        ax[0].cla()\n",
    "        Ishow = ((AI-torch.amin(AI,(1,2,3))[...,None,None])/(torch.amax(AI,(1,2,3))-torch.amin(AI,(1,2,3)))[...,None,None,None]).permute(1,2,3,0).clone().detach().cpu()\n",
    "        ax[0].imshow(  Ishow[0,...,0] ,extent=extentJ)\n",
    "        if pointsIt.shape[0] >0: ax[0].scatter(pointsIt[...,2].clone().detach().cpu(),pointsIt[...,1].clone().detach().cpu(),s=1,color='orange')\n",
    "        ax[0].set_title('space tformed source')\n",
    "\n",
    "        ax[1].cla()    \n",
    "        Ishow = STalign.clip(fAI.permute(1,2,3,0).clone().detach()/torch.max(J).item()).cpu()\n",
    "        ax[1].imshow(Ishow[0,...,0],extent=extentJ,vmin=0,vmax=1)\n",
    "        #ax[1].scatter(pointsIt[:,1].clone().detach().cpu(),pointsIt[:,0].clone().detach().cpu())\n",
    "        ax[1].set_title('contrast tformed source')\n",
    "        \n",
    "        ax[5].cla()\n",
    "        Ishow = STalign.clip( (fAI - J)/(torch.max(J).item())*3.0  ).permute(1,2,3,0).clone().detach().cpu()*0.5+0.5\n",
    "        ax[5].imshow(Ishow[0,...,0],extent=extentJ)\n",
    "        #ax[5].scatter(pointsIt[:,2].clone().detach().cpu(),pointsIt[:,1].clone().detach().cpu(),s=1,color='red')\n",
    "        #ax[5].scatter(pointsJt[:,1].clone().detach().cpu(),pointsJ[:,0].clone().detach().cpu(),,s=1,color='yellow')\n",
    "        ax[5].set_title('Error')\n",
    "\n",
    "        ax[2].cla()\n",
    "        Ishow = J.permute(1,2,3,0).cpu()/torch.max(J).item()\n",
    "        ax[2].imshow(Ishow[0,...,0],extent=extentJ,vmin=0,vmax=1)\n",
    "        if pointsIt.shape[0] >0: ax[2].scatter(pointsJ[...,2].clone().detach().cpu(),pointsJ[...,1].clone().detach().cpu(),s=1,color='red')\n",
    "        ax[2].set_title('Target')\n",
    "\n",
    "        ax[4].cla()\n",
    "        ax[4].imshow(STalign.clip(torch.stack((WM,WA,WB),-1).clone().detach()).cpu()[0],extent=extentJ)\n",
    "        #ax[4].scatter(pointsIt[:,2].clone().detach().cpu(),pointsIt[:,1].clone().detach().cpu())\n",
    "        #ax[4].scatter(pointsJt[:,2].clone().detach().cpu(),pointsJt[:,1].clone().detach().cpu())\n",
    "\n",
    "        ax[4].set_title('Weights')\n",
    "\n",
    "\n",
    "        toshow = v[0].clone().detach().cpu() # initial velocity, components are rgb\n",
    "        toshow /= torch.max(torch.abs(toshow))\n",
    "        toshow = toshow*0.5+0.5\n",
    "    #toshow = torch.cat((toshow,torch.zeros_like(toshow[...,0][...,None])),-1)   \n",
    "        ax[3].cla()\n",
    "        ax[3].imshow(STalign.clip(toshow)[toshow.shape[0]//2],extent=extentV)\n",
    "        ax[3].set_title('velocity')\n",
    "        \n",
    "        axE[0].cla()\n",
    "        axE[0].plot(Esave)\n",
    "        axE[0].legend(['E','EM','ER','EP'])\n",
    "        axE[0].set_yscale('log')\n",
    "        axE[1].cla()\n",
    "        axE[1].plot([e[:2] for e in Esave])\n",
    "        axE[1].legend(['E','EM'])\n",
    "        axE[1].set_yscale('log')\n",
    "        axE[2].cla()\n",
    "        axE[2].plot([e[2] for e in Esave])\n",
    "        axE[2].legend(['ER'])\n",
    "        axE[2].set_yscale('log')\n",
    "        if pointsIt.shape[0] >0:\n",
    "            axE[3].cla()\n",
    "            axE[3].plot([e[3] for e in Esave])\n",
    "            axE[3].legend(['EP'])\n",
    "            axE[3].set_yscale('log')\n",
    "        \n",
    "        \n",
    "        fig.canvas.draw()\n",
    "        figE.canvas.draw()\n",
    "\n",
    "    return {\n",
    "        'A': A.clone().detach(), \n",
    "        'v': v.clone().detach(), \n",
    "        'xv': xv, \n",
    "        'WM': WM.clone().detach(),\n",
    "        'WB': WB.clone().detach(),\n",
    "        'WA': WA.clone().detach(),\n",
    "        'Xs': Xs.clone().detach()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "# Running STalign #\n",
    "\n",
    "num_complete = 0\n",
    "transforms = []\n",
    "for i in range(len(targets)):\n",
    "    print(f'Beginning STalign for Target #{num_complete+1}')\n",
    "    transform = LDDMM_3D_LBGFS(\n",
    "        xI,I,xJs[i],Js[i], # DO NOT CHANGE\n",
    "        T=Ts[i],L=Ls[i], # DO NOT CHANGE\n",
    "        nt=nts[i], # number of time steps, increase for smoother transform at expense of time\n",
    "        niter=niters[i],\n",
    "        device=device, # DO NOT CHANGE\n",
    "        sigmaM = sigmaMs[i],\n",
    "        sigmaP = sigmaPs[i],\n",
    "        sigmaR = sigmaRs[i],\n",
    "        pointsI=points_atlas[i], # DO NOT CHANGE\n",
    "        pointsJ=points_target[i], # DO NOT CHANGE\n",
    "        a = a_s[i],\n",
    "    )\n",
    "    transforms.append(transform)\n",
    "    num_complete+=1\n",
    "%matplotlib inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Target Slice Segmentation #\n",
    "%matplotlib inline\n",
    "\n",
    "region_graphs = []\n",
    "for i,transform in enumerate(transforms):\n",
    "        At = transform['A']\n",
    "        v = transform['v']\n",
    "        xv = transform['xv']\n",
    "        Xs = transform['Xs']\n",
    "\n",
    "        vol = S\n",
    "        dxL = dxS\n",
    "        nL = vol.shape\n",
    "        xL = [np.arange(n)*d - (n-1)*d/2 for n,d in zip(nL,dxL)]\n",
    "\n",
    "        # next chose points to sample on\n",
    "        res = 10.0\n",
    "        XJ = np.stack(np.meshgrid(np.zeros(1),xJs[i][0],xJs[i][1],indexing='ij'),-1)\n",
    "\n",
    "        tform = STalign.build_transform3D(xv,v,At,direction='b',XJ=torch.tensor(XJ,device=At.device))\n",
    "\n",
    "        AphiL = STalign.interp3D(\n",
    "                xL,\n",
    "                torch.tensor(vol[None].astype(np.float64),dtype=torch.float64,device=tform.device),\n",
    "                tform.permute(-1,0,1,2),\n",
    "                mode='nearest',)[0,0].cpu().int()\n",
    "\n",
    "        region_graph = AphiL.numpy()\n",
    "        brain_regions_id = np.unique(region_graph)\n",
    "        region_graphs.append(region_graph)\n",
    "\n",
    "fig, ax = plt.subplots(len(targets),1,figsize=(10,4*len(targets)))\n",
    "for i in range(len(targets)):\n",
    "        if len(targets) == 1: ax = [ax]\n",
    "        seg = ski.segmentation.mark_boundaries(targets_ds[i],region_graphs[i], mode='thick', background_label=0, color=(255,0,0))\n",
    "        ax[i].imshow(seg, extent=extents_target[i])\n",
    "        if points_np[i].shape[1]:\n",
    "                ax[i].scatter(points_np[i][1,:,1],points_np[i][1,:,0],color='red', s=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual Adjustment via VisuAlign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packaging transformed atlas in a NIFTI\n",
    "shapes = np.array([r.shape for r in region_graphs])\n",
    "max_dims = [shapes[:,0].max(), shapes[:,1].max()]\n",
    "paddings = max_dims-shapes\n",
    "region_graphs_pad = np.array([np.pad(r, ((p[0],0),(0,p[1]))) for p,r in zip(paddings, region_graphs)]) # creating a homogenous 3d object containing the segmentations for each slice\n",
    "\n",
    "seg_hdr = nib.load(\"Data\\\\Atlases\\\\DAPI\\\\label_dapi.nii\").header\n",
    "seg_nifti_data = np.transpose(np.flip(region_graphs_pad, axis=(0,1)), (-1,0,1))\n",
    "seg_hdr_arr = seg_hdr.structarr\n",
    "seg_hdr_arr['regular'] = b''\n",
    "seg_hdr_arr['dim'] = np.array([3, seg_nifti_data.shape[0], seg_nifti_data.shape[1], seg_nifti_data.shape[2], 0, 0, 0, 0]) \n",
    "seg_hdr_arr['pixdim'] = np.array([1., 1, 1, 1, 0, 0, 0, 0])\n",
    "seg_hdr_arr['datatype'] = 8 # changed to represent int32, #TODO: if not working try for uint32\n",
    "seg_hdr_arr['bitpix'] = 32\n",
    "seg_hdr_arr['qoffset_x'] = 0\n",
    "seg_hdr_arr['qoffset_y'] = 0\n",
    "seg_hdr_arr['qoffset_z'] = 0\n",
    "seg_hdr_arr['srow_x'] = np.array([1,0,0,0])\n",
    "seg_hdr_arr['srow_y'] = np.array([0,1,0,0])\n",
    "seg_hdr_arr['srow_z'] = np.array([0,0,1,0])\n",
    "#seg_affine = nib.load(\"dapi_template_segmentation_full_with_origin.nii\").affine\n",
    "#seg_affine[0,0] = 0.03333334\n",
    "#seg_affine[2,2] = 0.03333334\n",
    "seg_affine = np.array([[1,0,0,0],\n",
    "                    [0,1,0,0],\n",
    "                    [0,0,1,0],\n",
    "                    [0,0,0,1]])\n",
    "\n",
    "seg_nifti = nib.Nifti1Image(seg_nifti_data, seg_affine, seg_hdr)\n",
    "nib.save(seg_nifti, join(\"VisuAlign-v0_9//custom_atlas.cutlas//labels.nii.gz\"))\n",
    "\n",
    "visualign_export_folder = 'EXPORT_VISUALIGN_HERE'\n",
    "if not os.path.exists(visualign_export_folder):\n",
    "    os.mkdir(visualign_export_folder)\n",
    "\n",
    "with open('CLICK_ME.json','w') as f:\n",
    "    f.write('{')\n",
    "    f.write('\"name\":\"\", ')\n",
    "    f.write('\"target\":\"custom_atlas.cutlas\", ')\n",
    "    f.write('\"aligner\": \"prerelease_1.0.0\", ')\n",
    "    f.write('\"slices\": [')\n",
    "    for i in range(len(targets)): \n",
    "        ski.io.imsave(f'DELETE_ME_{i}.jpg',targets_original[i])\n",
    "        f.write('{')\n",
    "        h = region_graphs[i].shape[0]\n",
    "        w = region_graphs[i].shape[1]\n",
    "        f.write(f'\"filename\": \"DELETE_ME_{i}.jpg\", ')\n",
    "        f.write(f'\"anchoring\": [0, {len(targets)-i-1}, {h}, {w}, 0, 0, 0, 0, -{h}], ')\n",
    "        f.write(f'\"height\": {h}, \"width\": {w}, ')\n",
    "        f.write('\"nr\": 1, \"markers\": []}')\n",
    "        if i < len(targets)-1: f.write(',')\n",
    "    f.write(']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running VisuAlign #\n",
    "# How to use:\n",
    "# run this cell, then clicke file>open, then navigate to the location where your input image is, select the .json file with the same name as your image (the cell above should print out the name)\n",
    "# then adjust as desired by placing markers with SPACE and dragging the markers to adjust the alignment\n",
    "# when satisfied, click file>extract\n",
    "!cd VisuAlign-v0_9/ & C:\\Users\\kebsc\\Documents\\Rishi\\LDM-brain-region-excision\\VisuAlign-v0_9\\bin\\java --module qnonlin/visualign.QNonLin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Region Boundaries from Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in final segmentation from VisuAlign #\n",
    "final_segmentations = []\n",
    "present_regions = []\n",
    "\n",
    "# Loading in color table\n",
    "with open('Data\\\\Rainbow 2017.json') as fp:\n",
    "    table = json.load(fp)\n",
    "region_names_nutil = [row['name'] for row in table]\n",
    "\n",
    "for i in range(len(targets)):\n",
    "    visualign_nl_flat_filename = f'{visualign_export_folder}\\\\DELETE_ME_{i}_nl.flat'\n",
    "    with open(visualign_nl_flat_filename, 'rb') as fp:\n",
    "        buffer = fp.read()\n",
    "    nDims = int(buffer[0])\n",
    "    shape = np.frombuffer(buffer, dtype=np.dtype('>i4'), offset=1, count=2) \n",
    "    data = np.frombuffer(buffer, dtype=np.dtype('>i2'), offset=9)\n",
    "    data = data.reshape(shape[::-1])\n",
    "    data = data[:-1,:-1]\n",
    "\n",
    "    rids = np.unique(data)\n",
    "    present_regions.extend(rids)\n",
    "    final_segmentations.append(data)\n",
    "\n",
    "present_regions = np.unique(present_regions)\n",
    "print(f\"{len(present_regions)} Regions Detected:\")\n",
    "for r in present_regions: \n",
    "    print(f'{r}:{region_names_nutil[r]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SELECTING REGIONS TO EXTRACT ###\n",
    "%matplotlib tk\n",
    "# If you have a list of regions (separated by line) to extract, paste it below\n",
    "rois_name_input = '''\n",
    "PASTE REGION LIST HERE\n",
    "'''\n",
    "\n",
    "final_segs_marked = [ski.segmentation.mark_boundaries(W_ds,seg, mode='thick', background_label=0, color=(0,0,0)) for W_ds,seg in zip(targets_ds,final_segmentations)]\n",
    "roi_names = []\n",
    "rois = []\n",
    "reg_colors=['red','yellow','green','orange','brown','white','black']\n",
    "\n",
    "class Region_Picker():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.index = 0\n",
    "        self.show_seg()\n",
    "\n",
    "        # adding prev and next button\n",
    "        ax_prev = self.fig.add_axes([0.7,0.05,0.1,0.1])\n",
    "        ax_next = self.fig.add_axes([0.8,0.05,0.1,0.1])\n",
    "        self.prev_btn = mpl.widgets.Button(ax_prev, label='Previous')\n",
    "        self.next_btn = mpl.widgets.Button(ax_next, label='Next')\n",
    "        self.prev_btn.on_clicked(self.on_prev)\n",
    "        self.next_btn.on_clicked(self.on_next)\n",
    "\n",
    "        self.fig.canvas.mpl_connect('button_press_event', self.onclick);\n",
    "        self.move_bind = self.fig.canvas.mpl_connect('motion_notify_event', self.onmove)\n",
    "    \n",
    "    def show_seg(self):\n",
    "        self.ax.clear()\n",
    "        if len(rois) == 0:\n",
    "            self.ax.imshow(final_segs_marked[self.index])\n",
    "        else:\n",
    "            data = final_segmentations[self.index]\n",
    "            data_regions = np.zeros_like(data)\n",
    "            for roi in rois: data_regions += (data==roi).astype(int)\n",
    "            data_regions = np.multiply(data_regions,data)\n",
    "            self.ax.imshow(ski.color.label2rgb(data_regions,final_segs_marked[self.index], \n",
    "                                               bg_label=0,bg_color=None,saturation=1, \n",
    "                                               alpha=.7,image_alpha=1, colors=reg_colors))\n",
    "        plt.draw()\n",
    "\n",
    "    def on_prev(self,event):\n",
    "        self.index -= 1\n",
    "        self.index %= len(targets)\n",
    "        self.show_seg()\n",
    "\n",
    "    def on_next(self,event):\n",
    "        self.index += 1\n",
    "        self.index %= len(targets)\n",
    "        self.show_seg()\n",
    "\n",
    "    def onclick(self, event):\n",
    "        if event.inaxes != self.ax: return\n",
    "        x,y = int(event.xdata), int(event.ydata)\n",
    "        curr_roi = final_segmentations[self.index][y,x]\n",
    "        if curr_roi == 0: return\n",
    "        curr_roi_name = region_names_nutil[curr_roi]\n",
    "        if event.button == 1:\n",
    "            if curr_roi not in rois:\n",
    "                rois.append(curr_roi)\n",
    "                roi_names.append(curr_roi_name)\n",
    "                self.show_seg()\n",
    "                msg(f'{curr_roi_name} added')\n",
    "            else:\n",
    "                msg(f'{curr_roi_name} is already added')\n",
    "        elif event.button == 3:\n",
    "            if curr_roi in rois:\n",
    "                rois.remove(curr_roi)\n",
    "                roi_names.remove(curr_roi_name)\n",
    "                self.show_seg()\n",
    "                msg(f'{curr_roi_name} removed')\n",
    "            else:\n",
    "                msg(f'{curr_roi_name} is not in list')\n",
    "\n",
    "    def onmove(self, event):\n",
    "        if event.inaxes:\n",
    "            x,y = int(event.xdata), int(event.ydata)\n",
    "            curr_roi_name = region_names_nutil[final_segmentations[self.index][y,x]]\n",
    "            self.ax.set_title(curr_roi_name)\n",
    "            plt.draw()\n",
    "    \n",
    "def msg(message):\n",
    "    clear_output()\n",
    "    print(message)\n",
    "\n",
    "if rois_name_input != '\\nPASTE REGION LIST HERE\\n':\n",
    "    roi_names = rois_name_input.split('\\n')[1:-1]\n",
    "    rois = [region_names_nutil.index(roin) for roin in roi_names]\n",
    "\n",
    "rp = Region_Picker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERATE BOUNDARIES ###\n",
    "%matplotlib inline\n",
    "fig,ax = plt.subplots(len(targets),1, figsize=(10,4*len(targets)))\n",
    "for i in range(len(targets)): ax[i].imshow(targets_ds[i])\n",
    "\n",
    "region_bounds = [{} for t in targets]\n",
    "for i,roi in enumerate(rois):\n",
    "    for index in range(len(targets)):\n",
    "        pts = np.argwhere(final_segmentations[index]==roi)\n",
    "        if pts.shape[0] == 0: continue # skip if no points found\n",
    "        \n",
    "        cores,labels = dbscan(pts, eps=2, min_samples=5, metric='manhattan')\n",
    "\n",
    "        for l in set(labels):\n",
    "            if l == -1: continue # these points dont belong to any clusters\n",
    "            cluster = pts[labels==l]\n",
    "            shape_name = f'{region_names_nutil[roi]}_{l}'\n",
    "\n",
    "            hull = shapely.concave_hull(shapely.MultiPoint(cluster), 0.1) # get hull for cluster\n",
    "            \n",
    "            # only hulls defined as polygons can actually be cut out, other hulls will not be shown\n",
    "            if hull.geom_type == 'Polygon':\n",
    "                bound = shapely.get_coordinates(hull)\n",
    "                ax[index].plot(bound[:,1],bound[:,0], lw=2, c='black')\n",
    "                region_bounds[index][shape_name] = bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CALBIRATION POINT ANNOTATOR ###\n",
    "# left side is atlas slice\n",
    "# right side is target image\n",
    "# use mouse left click to mark a pair of corresponding points on atlas and target\n",
    "# right click removes the point\n",
    "# enter commits points to list\n",
    "# backspace removes most recently committed point\n",
    "# ctrl+backspace clears all points\n",
    "# COLOR KEY\n",
    "# red: new marked point, not committed\n",
    "# orange: most recently committed point, will be removed with backspace\n",
    "# black: committed point\n",
    "# when done selecting and committing points, simply move on to next cell\n",
    "%matplotlib tk\n",
    "\n",
    "calibration_pts = [[] for t in targets]\n",
    "\n",
    "new_pts = [[-1,-1] for t in targets]\n",
    "\n",
    "class Calibration_Interface():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.fig, self.ax = plt.subplots(1,1)\n",
    "        self.pt_sz = 4\n",
    "        self.index = 0\n",
    "        self.show_target()\n",
    "\n",
    "        # adding prev and next button\n",
    "        ax_prev = self.fig.add_axes([0.7,0.05,0.1,0.1])\n",
    "        ax_next = self.fig.add_axes([0.8,0.05,0.1,0.1])\n",
    "        self.prev_btn = mpl.widgets.Button(ax_prev, label='Previous')\n",
    "        self.next_btn = mpl.widgets.Button(ax_next, label='Next')\n",
    "        self.prev_btn.on_clicked(self.on_prev)\n",
    "        self.next_btn.on_clicked(self.on_next)\n",
    "        \n",
    "        self.fig.canvas.mpl_connect('button_press_event', self.onclick)\n",
    "        self.fig.canvas.mpl_connect('key_press_event', self.on_press)\n",
    "    \n",
    "    def show_target(self):\n",
    "        self.ax.clear()\n",
    "        self.ax.imshow(targets_ds[self.index])\n",
    "        self.ax.set_title(f'Marking calibration points for Target #{self.index+1}')\n",
    "        if len(calibration_pts[self.index]): \n",
    "            self.ax.scatter(np.array(calibration_pts[self.index])[:,0],np.array(calibration_pts[self.index])[:,1], color='lime', s=self.pt_sz) # plot prev selected points in white\n",
    "            self.ax.scatter(np.array(calibration_pts[self.index])[-1,0],np.array(calibration_pts[self.index])[-1,1], color='orange', s=self.pt_sz) # plot prev selected points in white\n",
    "        if new_pts[self.index][0] != -1:\n",
    "            self.ax.scatter(new_pts[self.index][0], new_pts[self.index][1], color='red', s=self.pt_sz)\n",
    "        plt.draw()\n",
    "\n",
    "    def on_prev(self,event):\n",
    "        self.index -= 1\n",
    "        self.index %= len(targets)\n",
    "        self.show_target()\n",
    "\n",
    "    def on_next(self,event):\n",
    "        self.index += 1\n",
    "        self.index %= len(targets)\n",
    "        self.show_target()\n",
    "\n",
    "    def onclick(self, event):\n",
    "        \n",
    "        if event.inaxes != self.ax: return\n",
    "        if event.xdata == None: return # clicked outside of plot\n",
    "        ix, iy = int(event.xdata), int(event.ydata) # get x and y data of pt\n",
    "        message = f'[{ix}, {iy}]'\n",
    "\n",
    "        if event.button == 1: # left click means add point at mouse location\n",
    "            new_pts[self.index][0] = ix\n",
    "            new_pts[self.index][1]= iy\n",
    "            message = f'point added at {new_pts}'\n",
    "        elif event.button == 3: # right click means remove previously created point\n",
    "            message = f'point removed at {new_pts}'\n",
    "            new_pts[self.index][0] = -1\n",
    "            new_pts[self.index][1] = -1\n",
    "\n",
    "        msg(message)\n",
    "        self.show_target() # refresh that axis to clear out any previously clicked on pts that were not committed\n",
    "\n",
    "    def on_press(self, event):\n",
    "        if event.key == 'enter': # enter key used to commit selected points to points list\n",
    "\n",
    "            if new_pts[self.index][0]==-1: # if missing a point in either axis, throw error\n",
    "                print(\"ERROR: attempted landmark save with one or more points missing!\")\n",
    "                return\n",
    "\n",
    "            # add new points to list, notify user, and clear out new points list\n",
    "            calibration_pts[self.index].append(new_pts[self.index].copy())\n",
    "            msg(f\"Added [{new_pts[self.index]}] to points list.\\n{len(calibration_pts[self.index])} marked points\")\n",
    "            new_pts[self.index][0] = -1\n",
    "            new_pts[self.index][1] = -1\n",
    "            self.show_target() # refresh both axes\n",
    "\n",
    "        elif event.key == 'backspace': # backspace key used to remove recently committed point\n",
    "            if len(calibration_pts[self.index]) == 0: return # if no points to remove, simply return\n",
    "            msg(f'Removed [{calibration_pts[self.index][-1]}]\\n{len(calibration_pts[self.index])} marked points') # user msg\n",
    "            \n",
    "            # remove last pair of poins\n",
    "            calibration_pts[self.index].pop(-1)\n",
    "            self.show_target() # refresh both axes\n",
    "\n",
    "# output msgs cleanly\n",
    "def msg(msg):\n",
    "    clear_output()\n",
    "    print(msg)\n",
    "\n",
    "interface = Calibration_Interface() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to xml #\n",
    "# will export to the input image folder\n",
    "# xml output names are simply the name of the input image with '_output.xml' appended to the end\n",
    "\n",
    "#formatting calibration points\n",
    "for index in range(len(targets)):\n",
    "    if len(calibration_pts[index]) != 3: \n",
    "        print(f'ERROR! YOU DID NOT MARK ENOUGH CALIBRATION POINTS FOR TARGET IMAGE #{index+1}')\n",
    "        break\n",
    "    \n",
    "    cp_copy = calibration_pts[index].copy()\n",
    "    cp_copy.sort()\n",
    "    cp_copy[1:] = sorted(cp_copy[1:], key=lambda a:a[1])\n",
    "    calibration_pts[index] = cp_copy.copy()\n",
    "   \n",
    "\n",
    "for index in range(len(targets)):\n",
    "    output_filename = f'{os.path.splitext(target_filenames[index])[0]}_output.xml'\n",
    "    with open(output_filename,'w') as file:\n",
    "        file.write(\"<ImageData>\\n\")\n",
    "        file.write(\"<GlobalCoordinates>1</GlobalCoordinates>\\n\")\n",
    "        for i,pt in enumerate(calibration_pts[index]):\n",
    "            file.write(f\"<X_CalibrationPoint_{i+1}>{pt[0]}</X_CalibrationPoint_{i+1}>\\n\")\n",
    "            file.write(f\"<Y_CalibrationPoint_{i+1}>{pt[1]}</Y_CalibrationPoint_{i+1}>\\n\")\n",
    "        file.write(f\"<ShapeCount>{len(region_bounds[index])}</ShapeCount>\\n\")\n",
    "\n",
    "        for i,shape in enumerate(region_bounds[index].values()):\n",
    "            file.write(f'<Shape_{i+1}>\\n')\n",
    "            file.write(f'<PointCount>{len(shape)+1}</PointCount>\\n')\n",
    "\n",
    "            for j in range(len(shape)+1):\n",
    "                file.write(f'<X_{j+1}>{shape[j%len(shape)][1]}</X_{j+1}>\\n')\n",
    "                file.write(f'<Y_{j+1}>{shape[j%len(shape)][0]}</Y_{j+1}>\\n')\n",
    "\n",
    "            file.write(f'</Shape_{i+1}>\\n')\n",
    "\n",
    "        file.write(\"</ImageData>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Up Files\n",
    "DO NOT RUN UNTIL COMPLETELY SATISFIED WITH BOUNDARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('CLICK_ME.json')\n",
    "os.remove('VisuAlign-v0_9/custom_atlas.cutlas/labels.nii.gz')\n",
    "os.remove('EXPORT_VISUALIGN_HERE/report.tsv')\n",
    "shutil.rmtree(visualign_export_folder)\n",
    "for f in glob.glob('*DELETE_ME*'): os.remove(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rishi_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
